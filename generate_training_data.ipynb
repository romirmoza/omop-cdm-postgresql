{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2 as pg\n",
    "import pandas as pd\n",
    "import pandas.io.sql as psql\n",
    "from datetime import timedelta\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to the database and fetch the person_visit_death_with_concepts table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_dir = '../../concept_codes_final/'\n",
    "training_dir = '../../training_small/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = training_dir + 'person.csv'\n",
    "df_person = pd.read_csv(filepath, usecols = ['year_of_birth',\n",
    "                                             'ethnicity_concept_id',\n",
    "                                             'person_id',\n",
    "                                             'month_of_birth',\n",
    "                                             'day_of_birth',\n",
    "                                             'race_concept_id',\n",
    "                                             'gender_concept_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = filepath = training_dir + 'visit_occurrence.csv'\n",
    "df_visits = pd.read_csv(filepath, usecols=['person_id',\n",
    "                                           'visit_start_date',\n",
    "                                           'preceding_visit_occurrence_id',\n",
    "                                           'visit_occurrence_id',\n",
    "                                           'visit_end_date',\n",
    "                                           'visit_concept_id',\n",
    "                                           'visit_type_concept_id',\n",
    "                                           'discharge_to_concept_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_person_visits = pd.merge(df_person, df_visits, on=['person_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_person\n",
    "del df_visits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = concept_dir + 'all_concepts.csv'\n",
    "df_concepts = pd.read_csv(filepath, usecols=['concept_name',\n",
    "                                             'concept_id',\n",
    "                                             'vocabulary_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concepts_race = df_concepts[df_concepts.vocabulary_id=='Race']\n",
    "df_concepts_race = df_concepts_race.drop(columns=['vocabulary_id'])\n",
    "df_concepts_race = df_concepts_race.rename(columns={'concept_id': 'race_concept_id',\n",
    "                                                    'concept_name': 'race_concept_name'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concepts_race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_person_visits_race = pd.merge(df_person_visits, df_concepts_race, on=['race_concept_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "del df_person_visits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concepts_visit = df_concepts[df_concepts.vocabulary_id=='Visit']\n",
    "df_concepts_visit = df_concepts_visit.drop(columns=['vocabulary_id'])\n",
    "df_concepts_visit = df_concepts_visit.rename(columns={'concept_id': 'visit_concept_id',\n",
    "                                                      'concept_name': 'visit_concept_name'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concepts_visit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_person_visits_race_concepts = \\\n",
    "pd.merge(df_person_visits_race, df_concepts_visit, on=['visit_concept_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = training_dir + 'death.csv'\n",
    "df_death = pd.read_csv(filepath, usecols=['person_id',\n",
    "                                          'death_date',\n",
    "                                          'death_datetime',\n",
    "                                          'death_type_concept_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df_person_visits_race_concepts, df_death, on=['person_id'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert dates to the correct datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['visit_start_date','visit_end_date', 'death_date']] = \\\n",
    "df[['visit_start_date','visit_end_date', 'death_date']].apply(pd.to_datetime, format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add visit_duration columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['visit_duration'] = df['visit_end_date'] - df['visit_start_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['visit_end_date'] = df['visit_end_date'].fillna(df['visit_start_date']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['death_date'] = df['death_date'].fillna(pd.Timestamp.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['death_date'] != pd.Timestamp.max].death_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_visit_start_date =  df['visit_start_date'].max()\n",
    "min_visit_start_date =  df['visit_start_date'].min()\n",
    "print(max_visit_start_date)\n",
    "print(min_visit_start_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_death_flag(x, window_size):\n",
    "    if x.death_date - x.visit_start_date < window_size and x.death_date - x.visit_start_date >= timedelta(days = 0):\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate windows of training data with window_id being the identifier. Every row has a death_in_next_window field that informs us whether the person dies in the next window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visit_types_count(x):\n",
    "    return pd.Series(dict(\n",
    "        inpatient_visit_count  = (x.visit_concept_name == 'Inpatient Visit').sum(),\n",
    "        outpatient_visit_count = (x.visit_concept_name == 'Outpatient Visit').sum(),\n",
    "        er_visit_count         = (x.visit_concept_name == 'Emergency Room Visit').sum()\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_data(df, window_size, window_start, group_by_var, date_var, agg_dict, rename_dict, apply_func, calc_death=0):\n",
    "    window_id = 0\n",
    "    while window_start < max_visit_start_date:\n",
    "        df_window = df[(df[date_var] >= window_start) & (df[date_var] < window_start + window_size)]\n",
    "        if(calc_death):\n",
    "            df_window['death_in_next_window'] = df_window.apply(lambda x: check_death_flag(x, window_size), axis=1)\n",
    "            df_window['old'] = window_start.year - df_window.year_of_birth\n",
    "\n",
    "        df_window[date_var] = (window_start + window_size) - df_window[date_var]\n",
    "        agg_df = df_window.groupby(group_by_var).agg(agg_dict).rename(columns=rename_dict)\n",
    "        apply_cols = df_window.groupby(group_by_var).apply(lambda x: apply_func(x))    \n",
    "        agg_df = agg_df.join(apply_cols)\n",
    "        agg_df['window_id'] = window_id\n",
    "        agg_df.reset_index(drop=True)\n",
    "        if not window_id:\n",
    "            windowed_data = agg_df.copy()\n",
    "        else:\n",
    "            windowed_data = pd.concat([windowed_data, agg_df], ignore_index=True)\n",
    "        window_id += 1\n",
    "        window_start += window_size\n",
    "    return windowed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = timedelta(days = 180)\n",
    "window_start = min_visit_start_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_dict = {'person_id': 'max',\n",
    "            'year_of_birth': 'max',\n",
    "            'visit_start_date': 'min',\n",
    "            'ethnicity_concept_id': 'max',\n",
    "            'race_concept_id': 'max',\n",
    "            'gender_concept_id': 'max',\n",
    "            'race_concept_name': 'max',\n",
    "            'visit_occurrence_id': 'nunique',\n",
    "            'visit_concept_name': 'count',\n",
    "            'visit_duration': 'sum',\n",
    "            'death_in_next_window': 'max',\n",
    "            'old': 'max'}\n",
    "\n",
    "rename_dict = {'visit_occurrence_id': 'number_of_visits',\n",
    "               'visit_start_date': 'days_since_latest_visit'}\n",
    "\n",
    "group_by_var = 'person_id'\n",
    "date_var = 'visit_start_date'\n",
    "apply_func = visit_types_count\n",
    "\n",
    "training_data = \\\n",
    "window_data(df, window_size, window_start, group_by_var, date_var, agg_dict, rename_dict, apply_func, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_data.days_since_latest_visit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = training_data.drop(['year_of_birth'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data[training_data.person_id == 2225]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data.window_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data.er_visit_count.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "f = open(\"features.txt\", \"r\")\n",
    "features = ''\n",
    "for x in f:\n",
    "    features += x\n",
    "    \n",
    "important_conditions = re.findall(r\"condition_concept_([0-9]+)\", features)\n",
    "important_procedures = re.findall(r\"procedure_concept_([0-9]+)\", features)\n",
    "important_drugs = re.findall(r\"drug_concept_([0-9]+)\", features)\n",
    "important_observations = re.findall(r\"observation_concept_([0-9]+)\", features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge with condition_occurrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = training_dir + 'condition_occurrence.csv'\n",
    "df = pd.read_csv(filepath, usecols = ['condition_occurrence_id',\n",
    "                                      'person_id', \n",
    "                                      'condition_concept_id',\n",
    "                                      'condition_start_date', \n",
    "                                      'condition_end_date',\n",
    "                                      'condition_type_concept_id',\n",
    "                                      'condition_status_concept_id',\n",
    "                                      'visit_occurrence_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['condition_end_date'] = df['condition_end_date'] if not 'NaT' else df['condition_start_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['condition_concept_id'] = df['condition_concept_id'].astype('Int64')\n",
    "df['condition_type_concept_id'] = df['condition_type_concept_id'].astype('Int64')\n",
    "df['condition_status_concept_id'] = df['condition_status_concept_id'].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['condition_concept_id'] = df['condition_concept_id'].apply(str)\n",
    "df['condition_type_concept_id'] = df['condition_type_concept_id'].apply(str)\n",
    "df['condition_status_concept_id'] = df['condition_status_concept_id'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['condition_start_date','condition_end_date']] = \\\n",
    "df[['condition_start_date','condition_end_date']].apply(pd.to_datetime, format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_condition_start_date =  df['condition_start_date'].max()\n",
    "min_condition_start_date =  df['condition_start_date'].min()\n",
    "print(max_condition_start_date)\n",
    "print(min_condition_start_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_condition_concept_id(x, important_features_set):\n",
    "    return pd.Series(dict(\n",
    "        condition_concept_id_list  = ', '.join(set(x.condition_concept_id).intersection(important_features_set)),\n",
    "        condition_type_concept_id_list  = ', '.join(set(x.condition_type_concept_id))\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_dict = {'person_id': 'max',\n",
    "            'condition_start_date': 'min',\n",
    "            'condition_status_concept_id': 'max'}\n",
    "\n",
    "rename_dict = {'condition_start_date': 'days_since_latest_condition'}\n",
    "\n",
    "group_by_var = 'person_id'\n",
    "date_var = 'condition_start_date'\n",
    "important_features_set = set(important_conditions)\n",
    "apply_func = lambda x: agg_condition_concept_id(x, important_features_set)\n",
    "\n",
    "df.condition_start_date = pd.to_datetime(df.condition_start_date, format='%Y-%m-%d')\n",
    "cond_occur_data = \\\n",
    "window_data(df, window_size, window_start, group_by_var, date_var, agg_dict, rename_dict, apply_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_occur_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.merge(training_data, cond_occur_data, on=['person_id', 'window_id'], how='left')\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del cond_occur_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge with procedure_occurrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = training_dir + 'procedure_occurrence.csv'\n",
    "df = pd.read_csv(filepath, usecols = ['procedure_occurrence_id',\n",
    "                                      'person_id',\n",
    "                                      'procedure_concept_id',\n",
    "                                      'procedure_date',\n",
    "                                      'procedure_type_concept_id',\n",
    "                                      'visit_occurrence_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['procedure_concept_id'] = df['procedure_concept_id'].astype('Int64')\n",
    "df['procedure_type_concept_id'] = df['procedure_type_concept_id'].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['procedure_concept_id'] = df['procedure_concept_id'].apply(str)\n",
    "df['procedure_type_concept_id'] = df['procedure_type_concept_id'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_procedure_concept_id(x, important_features_set):\n",
    "    return pd.Series(dict(\n",
    "        procedure_concept_id_list  = ', '.join(set(x.procedure_concept_id).intersection(important_features_set)),\n",
    "        procedure_type_concept_id_list  = ', '.join(set(x.procedure_type_concept_id))\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_dict = {'person_id': 'max',\n",
    "            'procedure_date': 'min'}\n",
    "\n",
    "rename_dict = {'procedure_date': 'days_since_latest_procedure'}\n",
    "\n",
    "group_by_var = 'person_id'\n",
    "date_var = 'procedure_date'\n",
    "important_features_set = set(important_procedures)\n",
    "apply_func = lambda x: agg_procedure_concept_id(x, important_features_set)\n",
    "\n",
    "df.procedure_date = pd.to_datetime(df.procedure_date, format='%Y-%m-%d')\n",
    "procedure_occur_data = \\\n",
    "window_data(df, window_size, window_start, group_by_var, date_var, agg_dict, rename_dict, apply_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_data = pd.merge(training_data, procedure_occur_data, on=['person_id', 'window_id'], how='left')\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del procedure_occur_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge with drug_exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = training_dir + 'drug_exposure.csv'\n",
    "df = pd.read_csv(filepath, usecols = ['drug_exposure_id',\n",
    "                                      'person_id',\n",
    "                                      'drug_concept_id',\n",
    "                                      'drug_exposure_start_date',\n",
    "                                      'drug_type_concept_id',\n",
    "                                      'quantity',\n",
    "                                      'visit_occurrence_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['drug_concept_id'] = df['drug_concept_id'].astype('Int64')\n",
    "df['drug_type_concept_id'] = df['drug_type_concept_id'].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['drug_concept_id'] = df['drug_concept_id'].apply(str)\n",
    "df['drug_type_concept_id'] = df['drug_type_concept_id'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_drug_concept_id(x, important_features_set):\n",
    "    return pd.Series(dict(\n",
    "        drug_concept_id_list  = ', '.join(set(x.drug_concept_id).intersection(important_features_set)),\n",
    "        drug_type_concept_id_list  = ', '.join(set(x.drug_type_concept_id))\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_dict = {'person_id': 'max',\n",
    "            'drug_exposure_start_date': 'min',\n",
    "            'quantity': 'sum'}\n",
    "\n",
    "rename_dict = {'drug_exposure_start_date': 'days_since_latest_drug_exposure',\n",
    "               'quantity': 'total_quantity_of_drugs'}\n",
    "\n",
    "group_by_var = 'person_id'\n",
    "date_var = 'drug_exposure_start_date'\n",
    "important_features_set = set(important_drugs)\n",
    "apply_func = lambda x: agg_drug_concept_id(x, important_features_set)\n",
    "\n",
    "df.drug_exposure_start_date = pd.to_datetime(df.drug_exposure_start_date, format='%Y-%m-%d')\n",
    "drug_exposure_data = \\\n",
    "window_data(df, window_size, window_start, group_by_var, date_var, agg_dict, rename_dict, apply_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.merge(training_data, drug_exposure_data, on=['person_id', 'window_id'], how='left')\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del drug_exposure_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge with observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = training_dir + 'observation.csv'\n",
    "df = pd.read_csv(filepath, usecols = ['observation_id',\n",
    "                                      'person_id',\n",
    "                                      'observation_concept_id',\n",
    "                                      'observation_date',\n",
    "                                      'observation_type_concept_id',\n",
    "                                      'value_as_string',\n",
    "                                      'value_as_concept_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dont know what to do with the columns value_as_string, value_as_concept_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['observation_concept_id'] = df['observation_concept_id'].astype('Int64')\n",
    "df['observation_type_concept_id'] = df['observation_type_concept_id'].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['observation_concept_id'] = df['observation_concept_id'].apply(str)\n",
    "df['observation_type_concept_id'] = df['observation_type_concept_id'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_observation_concept_id(x, important_features_set):\n",
    "    return pd.Series(dict(\n",
    "        observation_concept_id_list  = ', '.join(set(x.observation_concept_id).intersection(important_features_set)),\n",
    "        observation_type_concept_id_list  = ', '.join(set(x.observation_type_concept_id))\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_dict = {'person_id': 'max',\n",
    "            'observation_date': 'min'}\n",
    "\n",
    "rename_dict = {'observation_date': 'days_since_latest_observation'}\n",
    "\n",
    "group_by_var = 'person_id'\n",
    "date_var = 'observation_date'\n",
    "important_features_set = set(important_observations)\n",
    "apply_func = lambda x: agg_observation_concept_id(x, important_features_set)\n",
    "\n",
    "df.observation_date = pd.to_datetime(df.observation_date, format='%Y-%m-%d')\n",
    "observation_data = \\\n",
    "window_data(df, window_size, window_start, group_by_var, date_var, agg_dict, rename_dict, apply_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.merge(training_data, observation_data, on=['person_id', 'window_id'], how='left')\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del observation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(training_data)\n",
    "training_data.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_data.to_pickle(\"./training_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle the training_data\n",
    "import pickle\n",
    "pickle.dump(training_data, open( \"training_data.pkl\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unroll _list columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pickle.load( open( \"training_data.pkl\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a copy, preserve the original\n",
    "train = training_data.copy()\n",
    "col_num = train.shape[1]\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# unroll the _list columns and one-hot encode them\n",
    "lists = [c for c in train.columns if '_list' in c]\n",
    "for idx, row in train.iterrows():\n",
    "    for l in lists:\n",
    "        l_str = '_'.join(l.split('_')[:2])+'_'\n",
    "        l_items = row[l]\n",
    "        if isinstance(l_items, str):\n",
    "            l_items = l_items.split(',')\n",
    "            if isinstance(l_items, list) and l_items != ['']:\n",
    "                for c in l_items:\n",
    "                        train.loc[idx,l_str+str(c).strip()] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[col_num:].fillna(0, inplace=True)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(lists, axis=1)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('train_all.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
